{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS  Trascribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 \n",
    "import pandas as pd\n",
    "import boto3                                  #https://boto3.amazonaws.com/v1/documentation/api/latest/index.html\n",
    "import sagemaker\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "region = boto3.session.Session().region_name\n",
    "sess = sagemaker.session.Session()            #https://boto3.amazonaws.com/v1/documentation/api/latest/reference/core/session.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I could not run this part of the code. However, I could  run the rest of codes without this part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker import get_execution_role\n",
    "\n",
    "# role = get_execution_role()\n",
    "# print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### setting `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'vnsny-research-transcribeinput-test'  # replace your s3 bucket name\n",
    "input_folder = 'amazon-grant/amazon_grant-piolot-test'  # replace the folder name where you put audio files in s3 bucket\n",
    "output_folder = 'vnsny-research-transcribeoutput-test'  # replace the folder name where you want Transcribe to output in your s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #role = sagemaker.get_execution_role()\n",
    "\n",
    "# bucket = 'columbia-univ-data-transcribe'  # replace your s3 bucket name\n",
    "# input_folder = 'raw-audio'  # replace the folder name where you put audio files in s3 bucket\n",
    "# output_folder = 'vnsny-research-transcribeoutput-test'  # replace the folder name where you want Transcribe to output in your s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IPOD_HG_40921.mp4', 'IPOD_RN_04092021.mp4', 'IPOD_HG_40921.mp4', 'SONY_HG_04092021.MP3', 'SONY_LB_21721.MP3', 'SONY_TL_21621.MP3', 'SONY_TL_21821.MP3', 'SONY_withMirohphone.mp3', 'dual_channel_recording.m4a', 'SONY_MH_21921.MP3', 'SONY_RB_21921(2).MP3', 'SONY_TLA_22321.MP3', 'VOX_TLA_22321 copy.MP3']\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "s3_response = s3.list_objects_v2(           #Returns some or all (up to 1,000) of the objects in a bucket with each request\n",
    "    Bucket = bucket,\n",
    "    Prefix = f'{input_folder}/'\n",
    ")\n",
    "\n",
    "file = []\n",
    "for i in range(len(s3_response['Contents'])-1):\n",
    "    file.append(s3_response['Contents'][i+1]['Key'].split('/')[-1])\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Transcribe job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sherry's code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcribe = boto3.client('transcribe')\n",
    "# all_jobs = []\n",
    "\n",
    "# for i in range(len(file)):\n",
    "#     now = datetime.now()\n",
    "#     time_now = now.strftime('%H.%M.%S')\n",
    "#     job_name = f'transcribe-jid-{file[i]}-{time_now}'\n",
    "#     all_jobs.append(job_name)\n",
    "#     media_uri = f's3://{bucket}/{input_folder}/{file[i]}'\n",
    "#     transcribe.start_transcription_job(\n",
    "#         TranscriptionJobName = job_name,\n",
    "#         MediaFormat = 'wav',\n",
    "#         Media = {'MediaFileUri': media_uri},\n",
    "#         LanguageCode = 'en-US',\n",
    "#         OutputBucketName = bucket,\n",
    "#         OutputKey = f'{output_folder}/'\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### adding the setting information\n",
    "The file format was in mp4. Additioanally, we needed the speaker identification \n",
    "        for the transcription, so I added the information in the setting section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maryam Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ordinary\n",
    "transcribe = boto3.client('transcribe')\n",
    "all_jobs = []\n",
    "\n",
    "# for i in range(len(file)):\n",
    "now = datetime.now()\n",
    "time_now = now.strftime('%H.%M.%S')\n",
    "job_name = f'transcribe-jid-dual_channel_recording.m4a-{time_now}'\n",
    "all_jobs.append(job_name)\n",
    "# media_uri = f's3://{bucket}/{input_folder}/{file[i]}'\n",
    "    \n",
    "transcribe.start_transcription_job(\n",
    "    TranscriptionJobName = job_name,\n",
    "    MediaFormat = 'mp4',\n",
    "    Media = {'MediaFileUri': f\"s3://vnsny-research-transcribeinput-test/amazon-grant/amazon_grant-piolot-test/dual_channel_recording.m4a\"},\n",
    "    LanguageCode = 'en-US',\n",
    "    OutputBucketName = bucket,\n",
    "    OutputKey = f'{output_folder}/',\n",
    "    # format of the output\n",
    "    Settings={\n",
    "        'ShowSpeakerLabels': True,           # clarify the label of the speaker\n",
    "        'MaxSpeakerLabels': 2,               # number of thesspeakers in the file\n",
    "        'ChannelIdentification': False,      # if the voice recorders has channel\n",
    "        'ShowAlternatives': False,           # not sure about it\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check job status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sherry's Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finish = False\n",
    "# while not finish:\n",
    "#     finish_status = [False] * len(file)\n",
    "#     for i in range(len(file)):\n",
    "#         response = transcribe.get_transcription_job(\n",
    "#             TranscriptionJobName = all_jobs[i]\n",
    "#         )\n",
    "#         status = response['TranscriptionJob']['TranscriptionJobStatus']\n",
    "#         if status in ['COMPLETED', 'FAILED']:\n",
    "#             finish_status[i] = True\n",
    "#             print(f'Job {all_jobs[i]} status is {status}')\n",
    "#     if all(finish_status):\n",
    "#         finish = True\n",
    "#     else:\n",
    "#         time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maryam code\n",
    "Thanks for your codes for checking job status. It is great. I just simplified it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transcribe-jid-dual_channel_recording.m4a-10.22.16'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_jobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordinary\n",
    "# for i in range(len(file)):\n",
    "response = transcribe.get_transcription_job(\n",
    "    TranscriptionJobName = all_jobs[0]\n",
    ")\n",
    "#     status = response['TranscriptionJob']['TranscriptionJobStatus']\n",
    "#     if status in ['COMPLETED', 'FAILED']:\n",
    "#         finish_status[0] = True\n",
    "#         print(f'Job {all_jobs[0]} status is {status}')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = ['dual_channel_recording.m4a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sherry's codes to extract content, cofidence, start_time, end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript_text_and_timestamps(bucket_name, file_name):\n",
    "    \"\"\"take json file from S3 bucket and returns a tuple of:\n",
    "       entire transcript, list object of tuples of timestamp and individual sentences\n",
    "    \n",
    "    Args:\n",
    "        bucket_name (str): name of s3 bucket\n",
    "        file_name (str): name of file\n",
    "    Returns:\n",
    "        (\n",
    "        entire_transcript: str,\n",
    "        sentences_and_times: [ {start_time (sec) : float,\n",
    "                                end_time (sec)   : float,\n",
    "                                sentence         : str,\n",
    "                                min_confidence   : float (minimum confidence score of that sentence)\n",
    "                                } ],\n",
    "        confidences:  [ {start_time (sec) : float,\n",
    "                         end_time (sec)   : float,\n",
    "                         content          : str, (single word/phrase)\n",
    "                         confidence       : float (confidence score of the word/phrase)\n",
    "                         } ],\n",
    "        scores: list of confidence scores\n",
    "        )\n",
    "    \"\"\"\n",
    "    s3_clientobj = s3.get_object(Bucket=bucket_name, Key=file_name)\n",
    "    s3_clientdata = s3_clientobj[\"Body\"].read().decode(\"utf-8\")\n",
    "\n",
    "    original = json.loads(s3_clientdata)\n",
    "    print(original)\n",
    "    items = original[\"results\"][\"items\"]\n",
    "    entire_transcript = original[\"results\"][\"transcripts\"]\n",
    "\n",
    "    sentences_and_times = []\n",
    "    temp_sentence = \"\"\n",
    "    temp_start_time = 0\n",
    "    temp_min_confidence = 1.0\n",
    "    newSentence = True\n",
    "    \n",
    "    confidences = []\n",
    "    scores = []\n",
    "\n",
    "    i = 0\n",
    "    for item in items:\n",
    "#         print(\"item:\", item)\n",
    "        # always add the word\n",
    "        if item[\"type\"] == \"punctuation\":\n",
    "            temp_sentence = (\n",
    "                temp_sentence.strip() + item[\"alternatives\"][0][\"content\"] + \" \"\n",
    "            )\n",
    "        else:\n",
    "            temp_sentence = temp_sentence + item[\"alternatives\"][0][\"content\"] + \" \"\n",
    "            temp_min_confidence = min(temp_min_confidence,\n",
    "                                      float(item[\"alternatives\"][0][\"confidence\"]))\n",
    "            confidences.append({\"start_time\": float(item[\"start_time\"]),\n",
    "                                \"end_time\": float(item[\"end_time\"]),\n",
    "                                \"content\": item[\"alternatives\"][0][\"content\"],\n",
    "                                \"confidence\": float(item[\"alternatives\"][0][\"confidence\"])\n",
    "                               })\n",
    "            scores.append(float(item[\"alternatives\"][0][\"confidence\"]))\n",
    "\n",
    "        # if this is a new sentence, and it starts with a word, save the time\n",
    "        if newSentence == True:\n",
    "            if item[\"type\"] == \"pronunciation\":\n",
    "                temp_start_time = float(item[\"start_time\"])\n",
    "            newSentence = False\n",
    "        # else, keep going until you hit a punctuation\n",
    "        else:\n",
    "            if (\n",
    "                item[\"type\"] == \"punctuation\"\n",
    "                and item[\"alternatives\"][0][\"content\"] != \",\"\n",
    "            ):\n",
    "                # end time of sentence is end_time of previous word\n",
    "                end_time = items[i-1][\"end_time\"] if i-1 >= 0 else items[0][\"end_time\"]\n",
    "                sentences_and_times.append(\n",
    "                    {\"start_time\": temp_start_time,\n",
    "                     \"end_time\": end_time,\n",
    "                     \"sentence\": temp_sentence.strip(),\n",
    "                     \"min_confidence\": temp_min_confidence\n",
    "                    }\n",
    "                )\n",
    "                # reset the temp sentence and relevant variables\n",
    "                newSentence = True\n",
    "                temp_sentence = \"\"\n",
    "                temp_min_confidence = 1.0\n",
    "                \n",
    "        i = i + 1\n",
    "        \n",
    "    sentences_and_times.append(\n",
    "                    {\"start_time\": temp_start_time,\n",
    "                     \"end_time\": confidences[-1][\"end_time\"],\n",
    "                     \"sentence\": temp_sentence.strip(),\n",
    "                     \"min_confidence\": temp_min_confidence\n",
    "                    }\n",
    "                )\n",
    "    return entire_transcript, sentences_and_times, confidences, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transcribe-jid-dual_channel_recording.m4a-10.22.16']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordinary\n",
    "for i in range(len(all_jobs)):\n",
    "    print(f'Parsing {all_jobs[i]}.json')\n",
    "#     file_name = f'{output_folder}/{all_jobs[i]}.json'\n",
    "    file_name ='/'.join(response['TranscriptionJob']['Transcript']['TranscriptFileUri'].split('/')[4:])\n",
    "    entire_transcript, sentences_and_times, confidences, scores = get_transcript_text_and_timestamps(bucket, file_name)\n",
    "    with open(f\"{file[i].split('.')[0]}-entire-transcript.json\", 'w') as f:\n",
    "        json.dump(entire_transcript, f)\n",
    "    with open(f\"{file[i].split('.')[0]}-sentencess.json\", 'w') as f:\n",
    "        json.dump(sentences_and_times, f)\n",
    "    with open(f\"{file[i].split('.')[0]}-words.json\", 'w') as f:\n",
    "        json.dump(confidences, f)\n",
    "        \n",
    "sentences_and_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Maryam code - create dataframe for sherry's output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"path_to_a_folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = sentences_and_times, columns=[\"start_time\", \"end_time\", \"min_confidence\", \"sentence\"])\n",
    "df.to_excel(path + \"dual_channel_sherry.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maryam code to extract speakers' labels, content, confidence, start_time and end_time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript_text(bucket_name, file_name):\n",
    "\n",
    "    s3_clientobj = s3.get_object(Bucket=bucket_name, Key=file_name)\n",
    "    s3_clientdata = s3_clientobj[\"Body\"].read().decode(\"utf-8\")\n",
    "\n",
    "    original = json.loads(s3_clientdata)\n",
    "    items_spk = original[\"results\"]['speaker_labels'][\"segments\"]\n",
    "    items_content = original[\"results\"][\"items\"]\n",
    "    entire_transcript = original[\"results\"][\"transcripts\"]\n",
    "    spk = []\n",
    "    for i in range(len(items_spk)):\n",
    "        for j in range(len(items_spk[i]['items'])):\n",
    "            spk.append(items_spk[i]['items'][j]['speaker_label'])\n",
    "    \n",
    "    items_cont = []\n",
    "    for i in range(len(items_content)):\n",
    "        items_content[i][\"content\"] = items_content[i][\"alternatives\"][0][\"content\"]\n",
    "        items_content[i][\"confidence\"] = items_content[i][\"alternatives\"][0][\"confidence\"]\n",
    "        items_content[i].pop(\"alternatives\", None)\n",
    "        if items_content[i][\"type\"] == \"punctuation\":\n",
    "            items_content[i-1]['content'] = items_content[i-1]['content'] + items_content[i]['content']\n",
    "            continue\n",
    "        items_cont.append(items_content[i])\n",
    "        \n",
    "    for i in range(len(items_cont)):\n",
    "        items_cont[i].pop(\"type\", None)\n",
    "        items_cont[i][\"speaker_label\"] = spk[i]\n",
    "    \n",
    "    return items_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>content</th>\n",
       "      <th>confidence</th>\n",
       "      <th>speaker_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.27</td>\n",
       "      <td>I'm</td>\n",
       "      <td>0.999</td>\n",
       "      <td>spk_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.75</td>\n",
       "      <td>okay.</td>\n",
       "      <td>0.787</td>\n",
       "      <td>spk_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.76</td>\n",
       "      <td>1.14</td>\n",
       "      <td>Thank</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spk_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.14</td>\n",
       "      <td>1.24</td>\n",
       "      <td>you</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spk_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.24</td>\n",
       "      <td>1.48</td>\n",
       "      <td>very</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spk_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2601</th>\n",
       "      <td>1132.38</td>\n",
       "      <td>1132.63</td>\n",
       "      <td>because</td>\n",
       "      <td>0.968</td>\n",
       "      <td>spk_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2602</th>\n",
       "      <td>1132.63</td>\n",
       "      <td>1132.76</td>\n",
       "      <td>the</td>\n",
       "      <td>0.96</td>\n",
       "      <td>spk_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>1132.76</td>\n",
       "      <td>1133.02</td>\n",
       "      <td>weather</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spk_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>1133.02</td>\n",
       "      <td>1133.2</td>\n",
       "      <td>was</td>\n",
       "      <td>0.986</td>\n",
       "      <td>spk_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2605</th>\n",
       "      <td>1133.2</td>\n",
       "      <td>1133.76</td>\n",
       "      <td>shitty.</td>\n",
       "      <td>0.531</td>\n",
       "      <td>spk_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2606 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     start_time end_time  content confidence speaker_label\n",
       "0          0.04     0.27      I'm      0.999         spk_1\n",
       "1          0.27     0.75    okay.      0.787         spk_1\n",
       "2          0.76     1.14    Thank        1.0         spk_1\n",
       "3          1.14     1.24      you        1.0         spk_1\n",
       "4          1.24     1.48     very        1.0         spk_1\n",
       "...         ...      ...      ...        ...           ...\n",
       "2601    1132.38  1132.63  because      0.968         spk_0\n",
       "2602    1132.63  1132.76      the       0.96         spk_0\n",
       "2603    1132.76  1133.02  weather        1.0         spk_0\n",
       "2604    1133.02   1133.2      was      0.986         spk_0\n",
       "2605     1133.2  1133.76  shitty.      0.531         spk_0\n",
       "\n",
       "[2606 rows x 5 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_time_spk = get_transcript_text(bucket, file_name)\n",
    "df_data = pd.DataFrame(data=sent_time_spk, columns=sent_time_spk[0].keys())\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.to_excel(path + \"dual_channel_mary.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip using scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting mp4 to wav file for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50207744,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "m4afile = AudioSegment.from_file(path+\"dual_channel_recording.m4a\")\n",
    "np.array(m4afile.get_array_of_samples()).shape\n",
    "# m4afile.export(path+\"dual_c_r.wav\", format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile\n",
    "import numpy\n",
    "\n",
    "\n",
    "# file_name = f'{file[-1]}'\n",
    "# s3.download_file(Bucket=bucket, Key=f'{input_folder}/{file[-1]}', Filename=file_name)\n",
    "\n",
    "rate, data = scipy.io.wavfile.read(path+\"dual_c_r.wav\")\n",
    "edit_point = numpy.array([[860.1, 862.87],[880.86, 883.45]])  # \"Most important, decrease the cigarette.\", \"I'll speak to you on Wednesday.\"\n",
    "edit_point = numpy.round(edit_point*rate)\n",
    "\n",
    "new_wav_file_list = []\n",
    "for elem in edit_point:\n",
    "    start = int(elem[0])\n",
    "    end = int(elem[1])\n",
    "    new_wav_file_list.extend(data[start:end])\n",
    "    \n",
    "new_wav_file = numpy.array(new_wav_file_list)\n",
    "scipy.io.wavfile.write(path+'clipped.wav', rate, new_wav_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.io.wavfile\n",
    "# import numpy\n",
    "\n",
    "\n",
    "\n",
    "# file_name = f'{file[-1]}'\n",
    "# s3.download_file(Bucket=bucket, Key=f'{input_folder}/{file[-1]}', Filename=file_name)\n",
    "\n",
    "# rate, data = scipy.io.wavfile.read(file_name)\n",
    "# edit_point = numpy.array([[860.1, 862.87],[880.86, 883.45]])  # \"Most important, decrease the cigarette.\", \"I'll speak to you on Wednesday.\"\n",
    "# edit_point = numpy.round(edit_point*rate)\n",
    "\n",
    "# new_wav_file_list = []\n",
    "# for elem in edit_point:\n",
    "#     start = int(elem[0])\n",
    "#     end = int(elem[1])\n",
    "#     new_wav_file_list.extend(data[start:end])\n",
    "    \n",
    "# new_wav_file = numpy.array(new_wav_file_list)\n",
    "# scipy.io.wavfile.write('clipped.wav', rate, new_wav_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
